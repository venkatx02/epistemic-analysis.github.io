[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Epistemic Analysis Project",
    "section": "",
    "text": "Welcome to the Epistemic Analysis Project! \nThe Epistemic Analysis Project is a research initiative exploring the application of computational methods to identify and analyze the epistemological patterns in modern discourse from spaces such as social media, customer reviews, or political debates. This project seeks to develop language-based models capable of detecting these epistemological frameworks in contemporary texts, where ideas are often expressed in fragmented and evolving language. Currently, the focus is on building a reliable classifier that can identify the proportions of rationalism and empiricism in texts, although other schools of thought in epistemology will be systematically included in future phases of this project."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "author.html",
    "href": "author.html",
    "title": "About Author",
    "section": "",
    "text": "Hello,\nMy name is Venkat, and I’m a graduate student in the Data Analytics and Computational Social Science (DACSS) program at the University of Massachusetts Amherst. With a bachelor’s degree in computer science and some experience in the corporate world, I’ve developed expertise in web application development and machine learning. Now, I have landed into computational social science which combines computer science and data science with social sciences.\nMy research focuses on methodology rather than being domain-specific. However, I’m passionate about working across diverse domains, as it fuels my curiosity and enhances my adaptability and learning capabilities. Broadly, my interests are in and around information security, philosophy, political psychology, and international affairs. I’m currently working on a few projects in which I study these topics: determinants of voting behavior in India, the characteristics of states/countries that make them form diplomatic ties and their results in maintaining their power, and epistemological traditions in modern discourse.\nApart from academics, I represented Hex Esports, Minus 40 Club and some other organizations in the PUBG MOBILE competitive scene as an academic esports player. I spend my leisure playing video games and cooking (such a stress busters). Occasionally, I like to travel and grab some memories in the form of photographs."
  },
  {
    "objectID": "posts/post-1.html",
    "href": "posts/post-1.html",
    "title": "An Introduction",
    "section": "",
    "text": "About me \nHello, and welcome to my first blog post! My name is Venkat, and I’m a graduate student in the Data Analytics and Computational Social Science (DACSS) program at the University of Massachusetts Amherst. With a bachelor’s degree in computer science and some experience in the corporate world, I’ve developed expertise in web application development and machine learning. Now, I have landed into computational social science which combines computer science and data science with social sciences.\nMy research focuses on methodology rather than being domain-specific. However, I’m passionate about working across diverse domains, as it fuels my curiosity and enhances my adaptability and learning capabilities. Broadly, my interests are in and around information security, philosophy, political psychology, and international affairs. I’m currently working on a few projects in which I study these topics: determinants of voting behavior in India, the characteristics of countries that lead them to engage in wars and their impacts, and epistemic analysis and classification of modern texts.\n Research Question \n How can language-based models identify rationalism and empiricism in modern texts, such as social media posts? \nRationalism and empiricism are two foundational epistemological traditions that have shaped philosophical thought for centuries. Rationalism emphasizes deductive reasoning and innate ideas, while empiricism focuses on sensory experience and inductive reasoning. My goal is to develop computational models that can detect these epistemological tendencies in contemporary discourse, such as social media posts, where ideas are often expressed in fragmented and evolving language.\nStudying this question is essential because understanding an individual’s philosophical perspective offers valuable insights into their reasoning patterns, decision-making, and broader worldviews. Rationalism and empiricism represent two foundational approaches to knowledge, shaping arguments in science, politics, business, and everyday discourse. Identifying these epistemological tendencies in modern texts, such as social media posts, enhances our understanding of how people construct arguments, interpret evidence, and engage with information. Such insights could have applications in fields ranging from political analysis, artificial intelligence, business, consumer behavior, education, journalism, and media, helping to refine models of persuasion, belief formation, and knowledge dissemination in the digital age.\nThe Corpus\nTo address this research question, an initial corpus has been compiled of texts explicitly discussing rationalism and empiricism. The primary sources for this corpus are books from Project Gutenberg, featuring works by key rationalist philosophers—René Descartes, Baruch Spinoza, and Gottfried Wilhelm Leibniz—as well as empiricists such as John Locke, George Berkeley, and David Hume. However, as philosophical discourse and linguistic patterns have evolved, the corpus will be expanded to include diverse texts from different periods and contexts. PhilPapers, a comprehensive index and bibliography of philosophy, is a potential source for expanding the corpus.\nCredits: https://philosophydata.com/bibliography.html\nWhy This Corpus?\nThis corpus provides a clear foundation for distinguishing rationalist and empiricist thought. By analyzing argument structures, linguistic patterns, and reasoning styles in classical texts, language models can be trained to recognize epistemological tendencies in contemporary discourse. The selected works offer clear examples of deductive reasoning and innate ideas in rationalism versus sensory-based, inductive reasoning in empiricism. The structured nature of philosophical writings makes them ideal for computational analysis, allowing for effective training and classification of texts based on their underlying epistemic perspectives. Extending the corpus with evolving interpretations in literature will ensure a more comprehensive model that accounts for linguistic shifts and variations in how rationalist and empiricist ideas are expressed, thereby improving the model’s applicability to modern texts like social media posts."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "On the Way\n\n\n\n\n\n\n\n\n\n\n\n2025-04-09\n\n\nVenkat Dasari\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Corpus - 2\n\n\n\n\n\n\n\n\n\n\n\n2025-03-26\n\n\nVenkat Dasari\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Corpus\n\n\n\n\n\n\n\n\n\n\n\n2025-02-26\n\n\nVenkat Dasari\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction\n\n\n\n\n\n\n\n\n\n\n\n2025-02-12\n\n\nVenkat Dasari\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-2.html",
    "href": "posts/post-2.html",
    "title": "Exploring the Corpus",
    "section": "",
    "text": "I’ll start by reframing the research question… (They say good research questions start with “Why?”)\n Research Question \n Why do people make certain assertions? \nThe research question, “Why do people make certain assertions?” aims to explore and understand how individuals, groups, or societies think about, acquire, and justify knowledge, including their beliefs about the nature of knowledge, truth, and evidence—what we’ll call “epistemic patterns.” These patterns can be identified by analyzing modern digital discourse from spaces such as social media, customer reviews, or debates. For example, when someone on social media says, “Vaccines are essential because clinical trials show they work”, they’re using an empiricist pattern. They trust evidence and real-world observations. On the other hand, someone who says, “Freedom of speech matters because it’s a natural right”, follows a rationalist pattern. They rely on logical reasoning and principles they believe are naturally true. By studying these patterns, we can better understand how people reason, what influences their beliefs, and how they persuade others.\nEpistemic patterns are basically the ways people back up their statements with reasons or evidence. These patterns reflect different beliefs people hold about knowledge, and they’re often grouped into pairs that represent opposite (or) partially opposite ways of thinking:\nEmpiricism and Rationalism: Empiricism means trusting what we can see, hear, or test through experience or experiments. Rationalism, on the other hand, means relying more on logical thinking or ideas that we think are naturally true, without needing proof from experience.\nFoundationalism and Coherentism: Foundationalism believes knowledge should start from basic truths, things we consider obviously true, and build from there. Coherentism says knowledge is valid if our ideas consistently fit together, like pieces in a puzzle.\nInternalism and Externalism: Internalism suggests knowledge depends mostly on what’s happening inside our minds, like our personal reasons or justifications. Externalism argues that knowledge also relies on outside facts or conditions we might not be fully aware of.\nSkepticism and Fallibilism: Skepticism questions whether we can ever truly know something for sure. Fallibilism agrees that absolute certainty is rare but adds that we can still trust our knowledge as long as we’re open to revising it when new evidence comes along.\nWhile these pairs represent opposing or partially opposing viewpoints, real-world reasoning rarely fits neatly into one category. Instead, people’s beliefs and arguments usually fall somewhere along a spectrum, blending different proportions of these ideas.\nFor starters, this project is focused on identifying proportions of rationalism and empiricism, although all other schools of thought will be systematically included in future phases of this project.\nThe initial goal of this project is to build a reliable classifier that can identify the proportions of rationalism and empiricism in modern texts. Inspired by the Philosophy Data project (https://philosophydata.com/), which focuses broadly on identifying philosophical tendencies, this project is specifically interested in detecting epistemic tendencies and knowledge patterns. To achieve this, we’ll use transformer-based language models like BERT and RoBERTa. We might also experiment with GPT models, although they’re not primarily designed for classification tasks. These models are pre-trained on large-scale text data, and we’ll further fine-tune them on carefully annotated examples of rationalist and empiricist language to improve their accuracy and performance for our specific classification task.\nThe classification and/or detection of epistemological tendencies in discourse using language models holds significant practical potential. For example, in politics, identifying how people reason helps analysts understand what’s behind different policies or voting behaviors. In business, knowing people’s reasoning styles can help predict how consumers make decisions or how they’ll respond to marketing. In education, recognizing student’s reasoning patterns can guide teachers in designing better lessons to develop critical thinking and evidence-assessment skills. In journalism and media, spotting these patterns can help identify misinformation or persuasive techniques, which leads to clearer and more informed public discussions.\nThe Corpus\nTo explore this research question, an initial corpus has been compiled using texts that explicitly discuss rationalism and empiricism. As a starting point, I’m using the corpus from the Philosophy Data Project (credits: https://philosophydata.com/bibliography.html), which includes works by key rationalist and empiricist philosophers. These texts are freely accessible through Project Gutenberg. Thanks to both Philosophy Data Project and Project Gutenberg for making my life easier :)\nBooks discussing Empiricism:\nBerkeley, George. A Treatise Concerning the Principles of Human Knowledge. 2009. Project Gutenberg, www.gutenberg.org/ebooks/4723.\nBerkeley, George. Three Dialogues between Hylas and Philonous in Opposition to Sceptics and Atheists. 2009. Project Gutenberg, www.gutenberg.org/ebooks/4724.\nHume, David. A Treatise of Human Nature. 2003. Project Gutenberg, www.gutenberg.org/ebooks/4705.\nHume, David. Dialogues Concerning Natural Religion. 2009. Project Gutenberg, www.gutenberg.org/ebooks/4583.\nLocke, John. An Essay Concerning Human Understanding. 2004. Project Gutenberg, www.gutenberg.org/ebooks/10615. 2 vols.\nLocke, John. Second Treatise of Government. 2010. Project Gutenberg, www.gutenberg.org/ebooks/7370.\nBooks discussing Rationalism:\nDescartes, René. A Discourse on Method. Translated by John Veitch. 2008. Project Gutenberg, www.gutenberg.org/ebooks/59.\nDescartes, René. Meditations on First Philosophy. Translated by Michael Moriarty, Oxford University Press, 2008.\nLeibniz, G.W.. Theodicy: Essays on the Goodness of God, the Freedom of Man, and the Origin of Evil. Translated by E.M. Huggard. 2005. Project Gutenberg, www.gutenberg.org/ebooks/17147.\nMalebranche, Nicolas. The Search After Truth. Edited by Thomas M. Lennon and Paul J. Olscamp, Cambridge University Press, 1997.\nSpinoza, Benedict de. Ethics. Translated by R.H.M. Elwes. 2003. Project Gutenberg, www.gutenberg.org/ebooks/3800.\nSpinoza, Benedict de. On the Improvement of the Understanding. Translated by R.H.M. Elwes. 1997. Project Gutenberg, www.gutenberg.org/ebooks/1016.\nHowever, there’s an important consideration: the linguistic patterns in these historical texts may differ significantly from those used in modern discourse. Some scholars argue that the way we communicate and reason today has evolved, raising questions about whether these older texts can effectively represent modern epistemic tendencies. A couple of ideas I currently have are:\nUsing the current texts to build an initial model for labeling modern texts, then refining the results through human supervision.\nExpanding the corpus with texts from PhilPapers, a comprehensive index and bibliography of philosophy, which covers philosophical concepts across various contexts and domains.\nCorpus Summary\nI have titled the file names starting with “E” for the empiricist texts and “R” for the rationalist texts. A summary of the corpus can be found in the image below:\n\nThe empiricist texts, Hume’s “A Treatise of Human Nature” (E3) and Locke’s “An Essay Concerning Human Understanding” (E5), and the rationalist texts, Leibniz’s “Theodicy” (R2) and Descartes’s “Meditations on First Philosophy” (R5) are significantly longer in their respective corpora with a word count of more than 170000.\nLeibniz’s “Theodicy” has a huge vocabulary size of 13,006 unique words, indicating a highly diverse lexicon and possibly complex conceptual content. Hume’s “A Treatise of Human Nature”, Descartes’s “Meditations on First Philosophy” and Locke’s “An Essay Concerning Human Understanding” also have a considerable vocabulary.\nEmpiricist texts generally range around 30-40 words per sentence, whereas rationalist texts show more variation, some with extremely long sentences and some shorter.\nCorpus Readability\n\nRationalist texts tend to be a bit easier to read. Empiricist texts are somewhat harder, meaning they’re probably denser or use more complex explanations. I believe these differences suggest that rationalist and empiricist authors write differently.\nGenerally, a Flesch reading ease score between 60 and 70 and a Flesch-Kincaid grade level of 8 are considered ideal for most content. However, our corpus does not fall into these benchmarks.\nBook-wise Word Frequencies\n\n\nIn the empiricist texts, unique words like “sense”, “perceived”, “experience”, and “objects” highlight their focus on sensory evidence and observation. Rationalist texts use distinct words such as “certain”, “truth”, “reason” and references to “god” reflecting their emphasis on logical certainty and innate truths. These unique words clearly show the differences in how each group thinks about and justifies knowledge. However, both corpora share some common high-frequency words, such as “one”, “idea” and “mind”. What do you think about this overlap?\nWord Frequency\n\nThe above bar graphs show the frequency of the top 10 words from both corpora rather than book-wise word frequencies. Although there are common words like “one” and “idea”, we can observe some distinctions like empiricist texts using “may” and “must” more frequently, whereas rationalist texts are using “would”. Another interesting thing is that empiricists are frequently refering to “mind” and rationalist are refering to both “mind” and “body” (also “thing”).\nI think the book-wise word frequencies gave us better insights about similarities within corpora and distinction between empiricist and rationalist texts.\nWord Cloud\n\nThe word clouds allow us to examine the top 200 words in both the empiricism and rationalism corpora. So, what do you think?\nBigram Frequency\n\nCommon pairs in the empiricism corpus include “simple ideas”, “every one”, “one another”, and “cause effect”. Frequent pairs in the rationalist texts are “objections replies”, “human body”, “human mind”, “idea god” and “clearly distinctly”. Although there are no identical pairs found in both corpora, Is there a linguistic distinction?\n(I’m probably going to need help from a linguistics major for this one!)\nTrigram Frequency\n\nAgain, there are no identical trigrams found in both corpora. However, interpreting these trigrams as meaningful phrases is tricky since stop words were removed. I tried analyzing without removing stop words, but then most trigrams ended up containing only stop words. Let me know what you think!"
  },
  {
    "objectID": "posts/post-3.html",
    "href": "posts/post-3.html",
    "title": "Exploring the Corpus - 2",
    "section": "",
    "text": "Research Question \n Why do people make certain assertions? \nThe research question, “Why do people make certain assertions?” aims to explore and understand how individuals, groups, or societies think about, acquire, and justify knowledge, including their beliefs about the nature of knowledge, truth, and evidence—what we’ll call “epistemic patterns.” These patterns can be identified by analyzing modern digital discourse from spaces such as social media, customer reviews, or debates. For example, when someone on social media says, “Vaccines are essential because clinical trials show they work”, they’re using an empiricist pattern. They trust evidence and real-world observations. On the other hand, someone who says, “Freedom of speech matters because it’s a natural right”, follows a rationalist pattern. They rely on logical reasoning and principles they believe are naturally true. By studying these patterns, we can better understand how people reason, what influences their beliefs, and how they persuade others.\nThe initial goal of this project is to build a reliable classifier that can identify the proportions of rationalism and empiricism in modern texts. Inspired by the Philosophy Data project (https://philosophydata.com/), which focuses broadly on identifying philosophical tendencies, this project is specifically interested in detecting epistemic tendencies and knowledge patterns. To achieve this, we’ll use transformer-based language models like BERT and RoBERTa. We might also experiment with GPT models, although they’re not primarily designed for classification tasks. These models are pre-trained on large-scale text data, and we’ll further fine-tune them on carefully annotated examples of rationalist and empiricist language to improve their accuracy and performance for our specific classification task.\nTo explore this research question, an initial corpus has been compiled using texts that explicitly discuss rationalism and empiricism. As a starting point, I’m using the corpus from the Philosophy Data Project (credits: https://philosophydata.com/bibliography.html), which includes works by key rationalist and empiricist philosophers. These texts are freely accessible through Project Gutenberg. Thanks to both Philosophy Data Project and Project Gutenberg for making my life easier :)\nThe book titles can be found in the previous blog.\nThese historical texts serve as a “ground truth” for identifying and labeling rationalist and empiricist language patterns, which I aim to generalize and detect in modern discourse in future phases of the project.\n Exploratory Text Analysis \nIn this section, I tried to examine the word frequency distributions (unigrams) and phrase usage (n-grams) to explore the (latent) thematic differences that could possibly represent empiricism and rationalism.\n\nIn the first visualization, I tried to look at the words that are more common across the texts, but giving a bit of freedom in terms of word frequency, to create clusters using K-means. Texts like E1, E2, E4, E6 (empiricist), and R1, R4 (rationalist) are tightly packed together, suggesting similar lexicon usage patterns. Meanwhile, Hume’s Treatise of Human Nature (E3) appears more spread out, indicating greater variability in its vocabulary. I then tried to be permissive in terms of document coverage while increasing the threshold for word frequency but no notable changes were found in the clusters.\n\nNext, I included unigrams, bigrams, and trigrams that appeared at least 10 times across 8 documents. With this richer representation, texts like R3 and R5 joined the central cluster alongside E1, E2, E4, E6, R1, and R4. However, this created more distance among E3, E5 and R2, likely because their phrase usage diverges more sharply from the rest. When I filtered to only high-frequency n-grams, the clusters reverted to looking more like the unigram-only model. This led me to think that maybe the multi-word expressions are less frequently shared across the corpus. Could phrases/ngrams actually be more useful for the classification process than just relying on words, as they provide better distinction?\n\nThe above dendrograms show results of hierarchical clustering based on the frequency of individual words and n-grams (1 to 3), respectively. These groupings reflect the same structure found in the K-Means models. Some empiricist and rationalist texts group together but others don’t, and that’s a bit surprising. Although we didn’t find distinct clusters, the results support how epistemic tendencies might be better understood as gradients rather than strict categories.\nLet us see if Wordfish models can help us find something better!\n\nUnlike clustering, which groups texts based on similarity, Wordfish estimates each document’s position along a latent dimension. Here, I used all stemmed words from the document-feature matrix (without trimming) to estimate these positions. What we see in the above image is a continuous scale that seems to align quite well with the epistemological divide we are interested in.\nWe find R5 and R2 sitting on the extreme right, given their strong rationalist leanings. R3, R4, and R1 follow closely behind. On the other side, E6, E3, E4, and E5 anchor the left side, representing empiricist tendencies. Interestingly, E1 and E2, written by the same author, show up closer to the middle, suggesting their language overlaps a bit more with the rationalist side than others in the empiricist group.\nThis smooth, ordered distribution is exactly the thing clustering struggled to reveal (Thanks to Wordfish). The wordfish results above support our argument that reasoning styles can fall along a spectrum rather than belonging to fixed groups.\n\nThe above plots show the wordfish feature discrimination: which words contribute the most to separating empiricist and rationalist texts along the latent dimension. The x-axis reflects how strongly a word influences a document’s position, while the y-axis reflects how frequently that word appears across the corpus.\nLeft side = more empiricist-weighted words; Right side = more rationalist-weighted words\nIn the first plot, words like “always”, “causes” and “much” appear closer to the left (empiricist-leaning?). On the right, words like “god”, “exist”, “thing”, “substance”, and “knowledge” (rationalist leaning).\nInterestingly, some words like “idea” and “mind” show up toward the center (should prolly be used a lot by George Berkeley), implying their use across both traditions but (possibly) in different contexts.\n Further Steps \nNow that I have enough evidence from the above results to support my major assumptions: empiricists and rationalists have distinct linguistic patterns, and these patterns can be identified as proportions or along a spectrum rather than as pure classes. I’ll be moving forward to build classification models. Although I’m over-excited to explore the transformer-based models, I’ll start with traditional machine learning approaches such as SVM, Naive Bayes, and ensemble models, depending on time constraints.\nCode and other supporting files can be found at: https://github.com/venkatx02/epistemic-analysis.github.io"
  },
  {
    "objectID": "supporting-files/clustering-scaling.html",
    "href": "supporting-files/clustering-scaling.html",
    "title": "clustering-scaling",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.2\n\n\nWarning: package 'forcats' was built under R version 4.4.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggplot2)\nlibrary(quanteda)\n\nWarning: package 'quanteda' was built under R version 4.4.3\n\n\nPackage version: 4.2.0\nUnicode version: 15.1\nICU version: 74.1\nParallel computing: 16 of 16 threads used.\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\n\nWarning: package 'quanteda.textmodels' was built under R version 4.4.3\n\nlibrary(quanteda.textplots)\n\nWarning: package 'quanteda.textplots' was built under R version 4.4.3\n\n\n\nfiles_path = \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus\"\nfiles = list.files(path = files_path, pattern = \"\\\\.txt$\", full.names = TRUE)\nfiles\n\n [1] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt\"                       \n [2] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt\"\n [3] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E3-HumeDavid-ATreatiseofHumanNature.txt\"                                                      \n [4] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E4-HumeDavid-DialoguesConcerningNaturalReligion.txt\"                                          \n [5] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt\"                                         \n [6] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/E6-LockeJohn-SecondTreatiseofGovernment.txt\"                                                  \n [7] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/R1-DescartesRené-ADiscourseonMethod.txt\"                                                      \n [8] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/R2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt\"        \n [9] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/R3-SpinozaBenedictde-Ethics.txt\"                                                              \n[10] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/R4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt\"                                  \n[11] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Full-Mixed Corpus/R5-DescartesRené-MeditationsonFirstPhilosophy.txt\"                                            \n\n\n\ntexts = sapply(files, function(file) paste(readLines(file, warn = FALSE), collapse = \" \"))\ncorpus = corpus(texts, docnames = basename(files))\nsummary(corpus)\n\nCorpus consisting of 11 documents, showing 11 documents:\n\n                                                                                          Text\n                        E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt\n E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt\n                                                       E3-HumeDavid-ATreatiseofHumanNature.txt\n                                           E4-HumeDavid-DialoguesConcerningNaturalReligion.txt\n                                          E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt\n                                                   E6-LockeJohn-SecondTreatiseofGovernment.txt\n                                                       R1-DescartesRené-ADiscourseonMethod.txt\n         R2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt\n                                                               R3-SpinozaBenedictde-Ethics.txt\n                                   R4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt\n                                             R5-DescartesRené-MeditationsonFirstPhilosophy.txt\n Types Tokens Sentences\n  4205  42918      1167\n  3296  42826      2589\n  8330 257027      6988\n  4417  41832      1228\n  7802 172218      4525\n  5038  65406      1596\n  2995  25426       284\n 13198 216075      7291\n  4191 108676      3694\n  2181  20157       477\n  8933 169295      4808\n\n\n\ntokens = tokens(corpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE)\ntokens = tokens_tolower(tokens)\ntokens = tokens_remove(tokens, stopwords(\"en\"))\ntokens = tokens_wordstem(tokens, language = \"english\")\ntokens = tokens_remove(\n  tokens,\n  pattern = \"^(?i)(m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})(ix|iv|v?i{0,3}))$\",\n  valuetype = \"regex\"\n)\nhead(tokens)\n\nTokens consisting of 6 documents.\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt :\n [1] \"produc\"   \"col\"      \"choat\"    \"html\"     \"version\"  \"al\"      \n [7] \"hain\"     \"treatis\"  \"concern\"  \"principl\" \"human\"    \"knowledg\"\n[ ... and 16,750 more ]\n\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt :\n [1] \"produc\"  \"col\"     \"choat\"   \"html\"    \"version\" \"al\"      \"hain\"   \n [8] \"three\"   \"dialogu\" \"hyla\"    \"philon\"  \"opposit\"\n[ ... and 16,271 more ]\n\nE3-HumeDavid-ATreatiseofHumanNature.txt :\n [1] \"treatis\"    \"human\"      \"natur\"      \"david\"      \"hume\"      \n [6] \"content\"    \"volum\"      \"introduct\"  \"author\"     \"book\"      \n[11] \"understand\" \"part\"      \n[ ... and 103,658 more ]\n\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt :\n [1] \"produc\"   \"col\"      \"choat\"    \"html\"     \"version\"  \"al\"      \n [7] \"hain\"     \"dialogu\"  \"concern\"  \"natur\"    \"religion\" \"david\"   \n[ ... and 17,144 more ]\n\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt :\n [1] \"essay\"      \"concern\"    \"human\"      \"understand\" \"four\"      \n [6] \"book\"       \"john\"       \"lock\"       \"imag\"       \"_quam\"     \n[11] \"bellum\"     \"est\"       \n[ ... and 66,117 more ]\n\nE6-LockeJohn-SecondTreatiseofGovernment.txt :\n [1] \"second\"  \"treatis\" \"govern\"  \"john\"    \"lock\"    \"digit\"   \"dave\"   \n [8] \"gowan\"   \"john\"    \"locke’\"  \"second\"  \"treatis\"\n[ ... and 24,726 more ]\n\n\n\n#tokens = tokens_ngrams(tokens, n = 1:3)\n#head(tokens)\n\n\ndfm = dfm(tokens) |&gt; dfm_trim(max_termfreq = 1000, min_docfreq = 6)\nhead(dfm)\n\nDocument-feature matrix of: 6 documents, 1,930 features (20.98% sparse) and 0 docvars.\n                                                                                               features\ndocs                                                                                            html\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                           1\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt    1\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                          0\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                              1\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                             0\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                      0\n                                                                                               features\ndocs                                                                                            version\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                              1\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt       1\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                             0\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                 1\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                                0\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                         0\n                                                                                               features\ndocs                                                                                            treatis\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                              9\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt       0\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                            11\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                 1\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                               10\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                         6\n                                                                                               features\ndocs                                                                                            concern\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                             30\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt      17\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                           350\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                40\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                              121\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                        23\n                                                                                               features\ndocs                                                                                            georg\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                            2\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt     1\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                           0\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                               0\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                              1\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                       0\n                                                                                               features\ndocs                                                                                            wherein\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                             26\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt      11\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                            32\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                 0\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                              115\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                        33\n                                                                                               features\ndocs                                                                                            chief\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                            8\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt     0\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                          18\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                               6\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                              6\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                      10\n                                                                                               features\ndocs                                                                                            error\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                           24\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt     2\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                          63\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                               6\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                             11\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                       0\n                                                                                               features\ndocs                                                                                            difficulti\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                                30\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt         29\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                              146\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                   29\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                                  34\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                            5\n                                                                                               features\ndocs                                                                                            scienc\n  E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                            20\n  E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt      9\n  E3-HumeDavid-ATreatiseofHumanNature.txt                                                           54\n  E4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                               20\n  E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                              11\n  E6-LockeJohn-SecondTreatiseofGovernment.txt                                                        0\n[ reached max_nfeat ... 1,920 more features ]\n\ntopfeatures(dfm)\n\n    suppos      order        way      clear    passion particular      never \n      1000        999        997        991        990        985        984 \n   general     matter       form \n       980        966        947 \n\n\n\ndfm_matrix = as.matrix(dfm)\nscaled_matrix = scale(dfm_matrix)\n\n\nkmeans_result = kmeans(scaled_matrix, centers = 2)\nclusters = as.factor(kmeans_result$cluster)\n\n\npca = prcomp(scaled_matrix)\npca_data = data.frame(pca$x[, 1:2])\npca_data$doc = rownames(scaled_matrix)\npca_data$doc_short = substr(pca_data$doc, 1, 2)\npca_data$cluster = as.factor(clusters)\npca_data\n\n                                                                                                     PC1\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                        -18.043566\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt -19.929050\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                        57.225328\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                           -12.620595\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                           20.140807\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                   -11.294419\nR1-DescartesRené-ADiscourseonMethod.txt                                                       -21.041439\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt          36.719775\nR3-SpinozaBenedictde-Ethics.txt                                                               -10.658204\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                                   -26.722939\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                               6.224302\n                                                                                                        PC2\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                          4.147215080\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt   4.586825696\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                        33.950054060\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                             5.299310362\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                            5.515180559\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                     2.865760292\nR1-DescartesRené-ADiscourseonMethod.txt                                                         2.345863379\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt         -41.412505438\nR3-SpinozaBenedictde-Ethics.txt                                                                -0.006384282\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                                     3.363481599\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                             -20.654801305\n                                                                                                                                                                                        doc\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                                               E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                                                                             E3-HumeDavid-ATreatiseofHumanNature.txt\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                                                     E4-HumeDavid-DialoguesConcerningNaturalReligion.txt\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                                                                   E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                                                                     E6-LockeJohn-SecondTreatiseofGovernment.txt\nR1-DescartesRené-ADiscourseonMethod.txt                                                                                                             R1-DescartesRené-ADiscourseonMethod.txt\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt                 R2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt\nR3-SpinozaBenedictde-Ethics.txt                                                                                                                             R3-SpinozaBenedictde-Ethics.txt\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                                                                     R4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                                                                         R5-DescartesRené-MeditationsonFirstPhilosophy.txt\n                                                                                              doc_short\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                               E1\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt        E2\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                              E3\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                  E4\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                                 E5\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                          E6\nR1-DescartesRené-ADiscourseonMethod.txt                                                              R1\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt                R2\nR3-SpinozaBenedictde-Ethics.txt                                                                      R3\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                                          R4\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                                    R5\n                                                                                              cluster\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                              2\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt       2\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                             1\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                                 2\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                                1\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                         2\nR1-DescartesRené-ADiscourseonMethod.txt                                                             2\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt               1\nR3-SpinozaBenedictde-Ethics.txt                                                                     2\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                                         2\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                                   2\n\n\n\nggplot(pca_data, aes(x = PC1, y = PC2, color = cluster, label = doc_short)) +\n  geom_point(size = 1) +\n  geom_text(vjust = 2, size = 3) +\n  stat_ellipse(aes(group = cluster), type = \"norm\", linetype = \"solid\", geom = \"polygon\", alpha = 0.1, size = 1) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ggtitle(\"K-Means Clustering - Full Feature Matrix\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nToo few points to calculate an ellipse\n\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\n\ndist_matrix = dist(scaled_matrix)\nhc_result = hclust(dist_matrix, method = \"ward.D2\")\n\n\nplot(hc_result, labels = substr(rownames(scaled_matrix), 1, 2), main = \"Hierarchical Clustering Dendrogram (FFM)\")\nrect.hclust(hc_result, k = 2, border = \"red\")\n\n\n\n\n\n\n\n\n\ndocnames(dfm) = sub(\"^(([^-]+-[^-]+)).*\", \"\\\\1\", docnames(dfm))\nwf_model = textmodel_wordfish(dfm)\nsummary(wf_model)\n\n\nCall:\ntextmodel_wordfish.dfm(x = dfm)\n\nEstimated Document Positions:\n                        theta       se\nE1-BerkeleyGeorge     0.01332 0.022949\nE2-BerkeleyGeorge     0.03690 0.024209\nE3-HumeDavid         -1.42852 0.008232\nE4-HumeDavid         -0.44620 0.022324\nE5-LockeJohn         -0.34755 0.011844\nE6-LockeJohn         -1.88527 0.014697\nR1-DescartesRené      0.20608 0.028181\nR2-LeibnizGW          0.68605 0.009330\nR3-SpinozaBenedictde  0.87371 0.013076\nR4-SpinozaBenedictde  0.84434 0.029300\nR5-DescartesRené      1.44715 0.007846\n\nEstimated Feature Scores:\n        html version treatis concern   georg wherein   chief  error difficulti\nbeta  0.6719  1.9075  0.1712 -0.3544  0.9609 -0.1744 -0.1777 0.5607    -0.1979\npsi  -0.9119 -0.7904  1.7111  3.8965 -0.4669  2.9556  1.6609 2.9959     3.3325\n       scienc   ground sceptic  atheism inquir   right  honour   nobl  order\nbeta 0.002923 0.003854 0.06349 -0.25740  0.225 -0.4626 -0.2284 0.2592 0.1811\npsi  2.598015 2.093863 2.53574  0.06066  1.631  3.7254  2.0171 0.7162 4.1982\n        lord perhap wonder   obscur  person  known  presum address  manner\nbeta -0.2086 0.1569 0.2595 -0.03813 -0.7169 0.3335 -0.4075  0.5468 -0.4409\npsi   1.2876 3.4669 2.3510  2.44947  3.6968 3.1733  0.8968  0.3776  3.6569\n     written someth design\nbeta  0.7084 0.6462 -0.357\npsi   1.3859 3.7790  2.574\n\n\n\nplot1 = textplot_scale1d(wf_model)\nplot1 + ggtitle(\"Wordfish Estimated Positions - Latent Scale\", subtitle = \"\")\n\n\n\n\n\n\n\n\n\nplot2 = textplot_scale1d(wf_model, margin = \"features\", highlighted = c(\"observ\", \"perceiv\", \"mind\", \"bodi\", \"idea\", \"think\", \"though\", \"man\", \"men\", \"principl\", \"god\", \"exist\", \"object\", \"relat\", \"thing\", \"reason\", \"moral\"))\nplot2 + ggtitle(\"Wordfish Feature Discrimination - Bigrams/Trigrams\", subtitle = \"\")"
  },
  {
    "objectID": "supporting-files/topic-modeling.html",
    "href": "supporting-files/topic-modeling.html",
    "title": "topic-modeling",
    "section": "",
    "text": "library(quanteda)\n\nWarning: package 'quanteda' was built under R version 4.4.3\n\n\nPackage version: 4.2.0\nUnicode version: 15.1\nICU version: 74.1\n\n\nParallel computing: 16 of 16 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(text2vec)\n\nWarning: package 'text2vec' was built under R version 4.4.3\n\n\n\nemp_path = \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism\"\nemp_files = list.files(path = emp_path, pattern = \"\\\\.txt$\", full.names = TRUE)\nemp_files\n\n[1] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt\"                       \n[2] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt\"\n[3] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E3-HumeDavid-ATreatiseofHumanNature.txt\"                                                      \n[4] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E4-HumeDavid-DialoguesConcerningNaturalReligion.txt\"                                          \n[5] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt\"                                         \n[6] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Empiricism/E6-LockeJohn-SecondTreatiseofGovernment.txt\"                                                  \n\n\n\nrat_path = \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism\"\nrat_files = list.files(path = rat_path, pattern = \"\\\\.txt$\", full.names = TRUE)\nrat_files\n\n[1] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism/R1-DescartesRené-ADiscourseonMethod.txt\"                                              \n[2] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism/R2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt\"\n[3] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism/R3-SpinozaBenedictde-Ethics.txt\"                                                      \n[4] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism/R4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt\"                          \n[5] \"C:/Users/venka/OneDrive/Desktop/Text as Data - Epistemic Analysis/Corpus/Rationalism/R5-DescartesRené-MeditationsonFirstPhilosophy.txt\"                                    \n\n\n\nemp_texts = sapply(emp_files, function(file) paste(readLines(file, warn = FALSE), collapse = \" \"))\nemp_corpus = corpus(emp_texts, docnames = basename(emp_files))\nsummary(emp_corpus)\n\nCorpus consisting of 6 documents, showing 6 documents:\n\n                                                                                          Text\n                        E1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt\n E2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt\n                                                       E3-HumeDavid-ATreatiseofHumanNature.txt\n                                           E4-HumeDavid-DialoguesConcerningNaturalReligion.txt\n                                          E5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt\n                                                   E6-LockeJohn-SecondTreatiseofGovernment.txt\n Types Tokens Sentences\n  4198  42907      1165\n  3289  42815      2587\n  8330 257027      6988\n  4410  41821      1226\n  7802 172218      4525\n  5038  65406      1596\n\n\n\nrat_texts = sapply(rat_files, function(file) paste(readLines(file, warn = FALSE), collapse = \" \"))\nrat_corpus = corpus(rat_texts, docnames = basename(rat_files))\nsummary(rat_corpus)\n\nCorpus consisting of 5 documents, showing 5 documents:\n\n                                                                                  Text\n                                               R1-DescartesRené-ADiscourseonMethod.txt\n R2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt\n                                                       R3-SpinozaBenedictde-Ethics.txt\n                           R4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt\n                                     R5-DescartesRené-MeditationsonFirstPhilosophy.txt\n Types Tokens Sentences\n  2995  25426       284\n 13187 216057      7291\n  4185 108665      3692\n  2174  20143       475\n  8933 169295      4808\n\n\n\nemp_tokens = tolower(emp_corpus)\nemp_tokens = word_tokenizer(emp_tokens)\nsummary(emp_tokens)\n\n                                                                                              Length\nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                         37449\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt  36555\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                       226156\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                            35983\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                          150207\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                    56560\n                                                                                              Class \nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                        -none-\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt -none-\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                       -none-\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                           -none-\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                          -none-\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                   -none-\n                                                                                              Mode     \nE1-BerkeleyGeorge-ATreatiseConcerningthePrinciplesofHumanKnowledge.txt                        character\nE2-BerkeleyGeorge-ThreeDialoguesbetweenHylasandPhilonousinOppositiontoScepticsandAtheists.txt character\nE3-HumeDavid-ATreatiseofHumanNature.txt                                                       character\nE4-HumeDavid-DialoguesConcerningNaturalReligion.txt                                           character\nE5-LockeJohn-AnEssayConcerningHumanUnderstanding.txt                                          character\nE6-LockeJohn-SecondTreatiseofGovernment.txt                                                   character\n\n\n\nemp_it = itoken(emp_tokens, progressbar = FALSE)\nemp_it\n\n&lt;itoken&gt;\n  Inherits from: &lt;CallbackIterator&gt;\n  Public:\n    callback: function (x) \n    clone: function (deep = FALSE) \n    initialize: function (x, callback = identity) \n    is_complete: active binding\n    length: active binding\n    move_cursor: function () \n    nextElem: function () \n    x: GenericIterator, iterator, R6\n\n\n\nemp_voc = create_vocabulary(emp_it)\nemp_voc = prune_vocabulary(emp_voc, term_count_min = 10)\ndim(emp_voc)\n\n[1] 3149    3\n\n\n\nemp_vectorizer =  vocab_vectorizer(emp_voc)\n\n\nemp_dtm = create_dtm(emp_it, emp_vectorizer, type = \"dgTMatrix\")\nsummary(emp_dtm)\n\n   Length     Class      Mode \n    18894 dgTMatrix        S4 \n\n\n\nemp_lda = LDA$new(n_topics = 10, doc_topic_prior = 0.1, topic_word_prior = 0.01)\nemp_lda\n\n&lt;WarpLDA&gt;\n  Inherits from: &lt;LDA&gt;\n  Public:\n    clone: function (deep = FALSE) \n    components: active binding\n    fit_transform: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n    get_top_words: function (n = 10, topic_number = 1L:private$n_topics, lambda = 1) \n    initialize: function (n_topics = 10L, doc_topic_prior = 50/n_topics, topic_word_prior = 1/n_topics, \n    plot: function (lambda.step = 0.1, reorder.topics = FALSE, doc_len = private$doc_len, \n    topic_word_distribution: active binding\n    transform: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n  Private:\n    calc_pseudo_loglikelihood: function (ptr = private$ptr) \n    check_convert_input: function (x) \n    components_: NULL\n    doc_len: NULL\n    doc_topic_distribution: function () \n    doc_topic_distribution_with_prior: function () \n    doc_topic_matrix: NULL\n    doc_topic_prior: 0.1\n    fit_transform_internal: function (model_ptr, n_iter, convergence_tol, n_check_convergence, \n    get_c_all: function () \n    get_c_all_local: function () \n    get_doc_topic_matrix: function (prt, nr) \n    get_topic_word_count: function () \n    init_model_dtm: function (x, ptr = private$ptr) \n    internal_matrix_formats: list\n    is_initialized: FALSE\n    n_iter_inference: 10\n    n_topics: 10\n    ptr: NULL\n    reset_c_local: function () \n    run_iter_doc: function (update_topics = TRUE, ptr = private$ptr) \n    run_iter_word: function (update_topics = TRUE, ptr = private$ptr) \n    seeds: 1624839384.98675 1774916653.34698\n    set_c_all: function (x) \n    set_internal_matrix_formats: function (sparse = NULL, dense = NULL) \n    topic_word_distribution_with_prior: function () \n    topic_word_prior: 0.01\n    transform_internal: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n    vocabulary: NULL\n\n\n\nemp_topic_distr = emp_lda$fit_transform(x = emp_dtm, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 25, progressbar = FALSE)\n\nINFO  [18:09:28.278] early stopping at 425 iteration\nINFO  [18:09:29.288] early stopping at 50 iteration\n\n\n\nbarplot(emp_topic_distr[1, ], xlab = \"topic\", ylab = \"proportion\", ylim = c(0, 1), names.arg = 1:ncol(emp_topic_distr))\n\n\n\n\n\n\n\n\n\nemp_lda$get_top_words(n = 10, topic_number = c(2L, 4L, 9L), lambda = 1)\n\n      [,1]   [,2]   [,3] \n [1,] \"i\"    \"the\"  \"of\" \n [2,] \"you\"  \"and\"  \"and\"\n [3,] \"the\"  \"in\"   \"to\" \n [4,] \"it\"   \"to\"   \"the\"\n [5,] \"in\"   \"of\"   \"in\" \n [6,] \"not\"  \"have\" \"are\"\n [7,] \"to\"   \"a\"    \"it\" \n [8,] \"a\"    \"you\"  \"not\"\n [9,] \"is\"   \"so\"   \"be\" \n[10,] \"phil\" \"any\"  \"by\" \n\n\n\nemp_lda$get_top_words(n = 10, topic_number = c(2L, 4L, 9L), lambda = 0.4)\n\n      [,1]         [,2]        [,3]      \n [1,] \"you\"        \"world\"     \"innate\"  \n [2,] \"phil\"       \"universe\"  \"duration\"\n [3,] \"hyl\"        \"ever\"      \"will\"    \n [4,] \"perceived\"  \"religion\"  \"are\"     \n [5,] \"things\"     \"animal\"    \"things\"  \n [6,] \"i\"          \"cleanthes\" \"names\"   \n [7,] \"your\"       \"human\"     \"man\"     \n [8,] \"exist\"      \"whole\"     \"body\"    \n [9,] \"unthinking\" \"cause\"     \"come\"    \n[10,] \"philonous\"  \"philo\"     \"and\"     \n\n\n\nrat_tokens = tolower(rat_corpus)\nrat_tokens = word_tokenizer(rat_tokens)\nsummary(rat_tokens)\n\n                                                                                      Length\nR1-DescartesRené-ADiscourseonMethod.txt                                                23060\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt 189633\nR3-SpinozaBenedictde-Ethics.txt                                                        88688\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                            16512\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                     145502\n                                                                                      Class \nR1-DescartesRené-ADiscourseonMethod.txt                                               -none-\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt -none-\nR3-SpinozaBenedictde-Ethics.txt                                                       -none-\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                           -none-\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                     -none-\n                                                                                      Mode     \nR1-DescartesRené-ADiscourseonMethod.txt                                               character\nR2-LeibnizGW-Theodicy_EssaysontheGoodnessofGod,theFreedomofMan,andtheOriginofEvil.txt character\nR3-SpinozaBenedictde-Ethics.txt                                                       character\nR4-SpinozaBenedictde-OntheImprovementoftheUnderstanding.txt                           character\nR5-DescartesRené-MeditationsonFirstPhilosophy.txt                                     character\n\n\n\nrat_it = itoken(rat_tokens, progressbar = FALSE)\nrat_it\n\n&lt;itoken&gt;\n  Inherits from: &lt;CallbackIterator&gt;\n  Public:\n    callback: function (x) \n    clone: function (deep = FALSE) \n    initialize: function (x, callback = identity) \n    is_complete: active binding\n    length: active binding\n    move_cursor: function () \n    nextElem: function () \n    x: GenericIterator, iterator, R6\n\n\n\nrat_voc = create_vocabulary(rat_it)\nrat_voc = prune_vocabulary(rat_voc, term_count_min = 10)\nrat_voc\n\nNumber of docs: 5 \n0 stopwords:  ... \nngram_min = 1; ngram_max = 1 \nVocabulary: \n        term term_count doc_count\n      &lt;char&gt;      &lt;int&gt;     &lt;int&gt;\n   1:    105         10         3\n   2:    115         10         2\n   3:    116         10         2\n   4:    135         10         2\n   5:    162         10         2\n  ---                            \n3285:    and      11472         5\n3286:   that      11677         5\n3287:     to      13415         5\n3288:     of      18118         5\n3289:    the      26993         5\n\ndim(rat_voc)\n\n[1] 3289    3\n\n\n\nrat_vectorizer =  vocab_vectorizer(rat_voc)\n\n\nrat_dtm = create_dtm(rat_it, rat_vectorizer, type = \"dgTMatrix\")\nsummary(rat_dtm)\n\n   Length     Class      Mode \n    16445 dgTMatrix        S4 \n\n\n\nrat_lda = LDA$new(n_topics = 10, doc_topic_prior = 0.1, topic_word_prior = 0.01)\nrat_lda\n\n&lt;WarpLDA&gt;\n  Inherits from: &lt;LDA&gt;\n  Public:\n    clone: function (deep = FALSE) \n    components: active binding\n    fit_transform: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n    get_top_words: function (n = 10, topic_number = 1L:private$n_topics, lambda = 1) \n    initialize: function (n_topics = 10L, doc_topic_prior = 50/n_topics, topic_word_prior = 1/n_topics, \n    plot: function (lambda.step = 0.1, reorder.topics = FALSE, doc_len = private$doc_len, \n    topic_word_distribution: active binding\n    transform: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n  Private:\n    calc_pseudo_loglikelihood: function (ptr = private$ptr) \n    check_convert_input: function (x) \n    components_: NULL\n    doc_len: NULL\n    doc_topic_distribution: function () \n    doc_topic_distribution_with_prior: function () \n    doc_topic_matrix: NULL\n    doc_topic_prior: 0.1\n    fit_transform_internal: function (model_ptr, n_iter, convergence_tol, n_check_convergence, \n    get_c_all: function () \n    get_c_all_local: function () \n    get_doc_topic_matrix: function (prt, nr) \n    get_topic_word_count: function () \n    init_model_dtm: function (x, ptr = private$ptr) \n    internal_matrix_formats: list\n    is_initialized: FALSE\n    n_iter_inference: 10\n    n_topics: 10\n    ptr: NULL\n    reset_c_local: function () \n    run_iter_doc: function (update_topics = TRUE, ptr = private$ptr) \n    run_iter_word: function (update_topics = TRUE, ptr = private$ptr) \n    seeds: 2132277708.01416 575980982.463576\n    set_c_all: function (x) \n    set_internal_matrix_formats: function (sparse = NULL, dense = NULL) \n    topic_word_distribution_with_prior: function () \n    topic_word_prior: 0.01\n    transform_internal: function (x, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 10, \n    vocabulary: NULL\n\n\n\nrat_topic_distr = rat_lda$fit_transform(x = rat_dtm, n_iter = 1000, convergence_tol = 0.001, n_check_convergence = 25, progressbar = FALSE)\n\nINFO  [18:09:36.732] early stopping at 400 iteration\nINFO  [18:09:37.572] early stopping at 50 iteration\n\n\n\nbarplot(rat_topic_distr[1, ], xlab = \"topic\", ylab = \"proportion\", ylim = c(0, 1), names.arg = 1:ncol(rat_topic_distr))\n\n\n\n\n\n\n\n\n\nrat_lda$get_top_words(n = 10, topic_number = c(4L, 8L, 9L), lambda = 1)\n\n      [,1]   [,2]   [,3]   \n [1,] \"the\"  \"i\"    \"to\"   \n [2,] \"that\" \"the\"  \"i\"    \n [3,] \"to\"   \"is\"   \"that\" \n [4,] \"a\"    \"from\" \"and\"  \n [5,] \"of\"   \"by\"   \"of\"   \n [6,] \"but\"  \"that\" \"which\"\n [7,] \"and\"  \"for\"  \"in\"   \n [8,] \"be\"   \"idea\" \"than\" \n [9,] \"not\"  \"a\"    \"them\" \n[10,] \"god\"  \"in\"   \"as\"   \n\n\n\nrat_lda$get_top_words(n = 10, topic_number = c(4L, 8L, 9L), lambda = 0.4)\n\n      [,1]     [,2]      [,3]        \n [1,] \"but\"    \"i\"       \"i\"         \n [2,] \"on\"     \"idea\"    \"to\"        \n [3,] \"cannot\" \"clearly\" \"than\"      \n [4,] \"that\"   \"exists\"  \"my\"        \n [5,] \"god\"    \"from\"    \"me\"        \n [6,] \"the\"    \"clear\"   \"them\"      \n [7,] \"sense\"  \"think\"   \"found\"     \n [8,] \"not\"    \"thing\"   \"principles\"\n [9,] \"be\"     \"is\"      \"much\"      \n[10,] \"a\"      \"by\"      \"use\""
  },
  {
    "objectID": "posts/post-4.html",
    "href": "posts/post-4.html",
    "title": "On the Way",
    "section": "",
    "text": "Alright, I guess it’s time for some reflection as we hit the final stretch of the project. From the beginning, my research has revolved around one big question:\nWhy do people make certain assertions?\nAt its core, this project is about understanding epistemic patterns. The real curiosity is: how do we know what we know? I’ve approached this by focusing on two major philosophical orientations: empiricism (relying on sensory experience and evidence) and rationalism (relying on reason and innate ideas). The hypothesis is that people’s reasoning styles show up in linguistic patterns, and with the right tools, we can detect and measure them.\nTo explore this question, an initial corpus has been compiled using texts that explicitly discuss rationalism and empiricism. As a starting point, I’m using the corpus from the Philosophy Data Project (credits: https://philosophydata.com/bibliography.html), which includes works by key rationalist and empiricist philosophers. These texts are freely accessible through Project Gutenberg. Thanks to both Philosophy Data Project and Project Gutenberg for making my life easier :)\nThe book titles can be found in the previous blog posts.\nThese historical texts serve as a “ground truth” for identifying and labeling rationalist and empiricist language patterns, which I aim to generalize and detect in modern discourse.\n\nRecap: previously on this project\nIn the previous blog posts, I explored the corpus using word frequencies, bigrams/trigrams, readability metrics, and document clustering. These analyses gave me early signs that linguistic distinctions between the two camps exist, but they aren’t always binary. The Wordfish model further supported this by showing that rationalist and empiricist texts tend to fall along a spectrum rather than fitting into fixed categories.\n\nFindings:\nA few takeaways have been especially compelling:\n\nDistinct vocabularies: Words like “experience”, “sense”, and “object” dominate empiricist texts, while “reason”, “truth”, and “god” show up frequently in rationalist ones.\nShared concepts: Terms like “idea” and “mind” appear across both traditions but in potentially different contexts.\nSpectrum over binary: Both clustering and Wordfish support the view that epistemic patterns aren’t just on/off labels but they exist on a spectrum or in varying proportions.\n\n\n\n\nTraditional Machine Learning Approach\nAfter those earlier findings, I moved on to training some basic supervised classifiers. To make that work, I needed more data, so I chopped up the books into smaller chunks, about three paragraphs each. That gave me a lot more samples to work with, and it also made sense because social media posts and online content aren’t nearly as long as full books. Chunking the texts felt like a good middle ground. Once chunked, the dataset looked something like this:\n\n\nIn total, I ended up with 2,692 chunks: 1,530 from empiricist texts and 1,162 from rationalist ones. The average chunk is around 372 words, which I think hits a nice balance: enough context to carry meaning, but not too long to be unrealistic for the kind of discourse I eventually want to analyze.\nI ran three basic classifiers: Naive Bayes, SVM, and Random Forest, on two different test sets. The results? Honestly, pretty wild.\n\n\nThe images above show the performance metrics of the three models when the test sample sizes were 20% and 30%, respectively. With a 20% test size, SVM hit 99.3% accuracy and an F1 score of 0.9924. At 30%, things got even more extreme. SVM reached 99.75% accuracy with an F1 score of 0.9975.\nThe performance has been suspiciously high, and I’m about 99% sure there’s some overfitting going on, just like we suspected. The training data probably isn’t diverse enough. These models might work great on classical philosophical texts, but I doubt they will perform the same when applied to modern, everyday language.\n\n\nFurther plans:\nI’m heading into the final phase with three priorities:\n\nEvaluate the classifiers on modern discourse (social media posts). One idea is to use these classifiers on the Mass-market Manifesto corpus (credits to Prof. Justin Gross) and see if there is a significant epistemological distinction between left vs right authors.\nExpand the dataset cautiously, by adding articles from PhilPapers.\nExplore the transformer-based models for more efficient and nuanced classification.\n\nUpdate: I heard back from the PhilPapers team. Unfortunately, they don’t have an API or any automated way to download multiple articles at once. So if I want to test on their annotated texts or include them in my training data, I’ll have to download each article manually. Not ideal, but it is what it is.\n\n\nChallenges:\nThere are still a few concerns on my radar:\nHow will these classifiers perform in real-world discourse where language is messier and more ambiguous?\nHow should I evaluate proportion-based predictions?\nManual data expansion is slow, and without an automated way to collect PhilPapers articles, scaling this research is a challenge."
  }
]